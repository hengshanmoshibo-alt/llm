# chat_robot.py
import streamlit as st
import ollama

st.set_page_config(page_title="DeepSeek èŠå¤©", page_icon="ğŸ¤–", layout="centered")

MODEL = "deepseek-r1:1.5b"

# ä¾§è¾¹æ åªç•™å‚æ•°å’Œæ¸…ç©ºæŒ‰é’®
with st.sidebar:
    st.title("âš™ï¸ è®¾ç½®")
    temperature = st.slider("Temperature", 0.0, 2.0, 0.8, 0.1)
    top_p = st.slider("Top P", 0.0, 1.0, 0.9, 0.05)
    max_tokens = st.slider("Max Tokens", 64, 2048, 512, 64)
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯"):
        st.session_state.messages = []
        st.rerun()

# å†å²æ¶ˆæ¯
if "messages" not in st.session_state:
    st.session_state.messages = []

st.title(f"ğŸ’¬ DeepSeek-R1 1.5B èŠå¤©")
st.caption(f"æ¸©åº¦ï¼š{temperature}")

# æ¸²æŸ“å†å²
for msg in st.session_state.messages:
    avatar = "ğŸ§‘" if msg["role"] == "user" else "ğŸ¤–"
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])

# è¾“å…¥&ç”Ÿæˆ
if prompt := st.chat_input("è¯·è¾“å…¥é—®é¢˜"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ§‘"):
        st.markdown(prompt)

    with st.chat_message("assistant", avatar="ğŸ¤–"):
        placeholder = st.empty()
        full = ""
        for chunk in ollama.chat(
            model=MODEL,
            messages=st.session_state.messages,
            stream=True,
            options={"temperature": temperature, "top_p": top_p, "num_predict": max_tokens}
        ):
            full += chunk["message"]["content"]
            placeholder.markdown(full + "â–Œ")
        placeholder.markdown(full)
    st.session_state.messages.append({"role": "assistant", "content": full})